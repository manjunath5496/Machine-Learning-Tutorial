<h2> Lecture Notes </h2>

<table class="tablewidth75" summary="See table caption for summary.">
<tbody>
<tr class="row">
<td>1</td>
<td>Introduction, linear classification, perceptron update rule (<a href="lec1.pdf" data-smd-id="s106">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>2</td>
<td>Perceptron convergence, generalization (<a href="lec2.pdf" data-smd-id="s107">PDF</a>)</td>
</tr>
<tr class="row">
<td>3</td>
<td>Maximum margin classification (<a href="lec3.pdf" data-smd-id="s108">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>4</td>
<td>Classification errors, regularization, logistic regression (<a href="lec4.pdf" data-smd-id="s109">PDF</a>)</td>
</tr>
<tr class="row">
<td>5</td>
<td>Linear regression, estimator bias and variance, active learning (<a href="lec5.pdf" data-smd-id="s110">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>6</td>
<td>Active learning (cont.), non-linear predictions, kernals (<a href="lec6.pdf" data-smd-id="s111">PDF</a>)</td>
</tr>
<tr class="row">
<td>7</td>
<td>Kernal regression, kernels (<a href="lec7.pdf" data-smd-id="s112">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>8</td>
<td>Support vector machine (SVM) and kernels, kernel optimization (<a href="lec8.pdf" data-smd-id="s113">PDF</a>)</td>
</tr>
<tr class="row">
<td>9</td>
<td>Model selection (<a href="lec9.pdf" data-smd-id="s114">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>10</td>
<td>Model selection criteria (<a href="lec10.pdf" data-smd-id="s115">PDF</a>)</td>
</tr>
<tr class="row">
<td>11</td>
<td>Description length, feature selection (<a href="lec11.pdf" data-smd-id="s116">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>12</td>
<td>Combining classifiers, boosting (<a href="lec12.pdf" data-smd-id="s117">PDF</a>)</td>
</tr>
<tr class="row">
<td>13</td>
<td>Boosting, margin, and complexity (<a href="lec13.pdf" data-smd-id="s118">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>14</td>
<td>Margin and generalization, mixture models (<a href="lec14.pdf" data-smd-id="s119">PDF</a>)</td>
</tr>
<tr class="row">
<td>15</td>
<td>Mixtures and the expectation maximization (EM) algorithm (<a href="lec15.pdf" data-smd-id="s120">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>16</td>
<td>EM, regularization, clustering (<a href="lec16.pdf" data-smd-id="s121">PDF</a>)</td>
</tr>
<tr class="row">
<td>17</td>
<td>Clustering (<a href="lec17.pdf" data-smd-id="s122">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>18</td>
<td>Spectral clustering, Markov models (<a href="lec18.pdf" data-smd-id="s123">PDF</a>)</td>
</tr>
<tr class="row">
<td>19</td>
<td>Hidden Markov models (HMMs) (<a href="lec19.pdf" data-smd-id="s124">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>20</td>
<td>HMMs (cont.) (<a href="lec20.pdf" data-smd-id="s125">PDF</a>)</td>
</tr>
<tr class="row">
<td>21</td>
<td>Bayesian networks (<a href="lec21.pdf" data-smd-id="s126">PDF</a>)</td>
</tr>
<tr class="alt-row">
<td>22</td>
<td>Learning Bayesian networks (<a href="lec22.pdf" data-smd-id="s127">PDF</a>)</td>
</tr>
<tr class="row">
<td>23</td>
<td>
<p>Probabilistic inference</p>
<p>Guest lecture on collaborative filtering (<a href="lec23.pdf" data-smd-id="s128">PDF</a>)</p>
</td>
</tr>
</tbody>
</table>
